# DocuBot

# Build on Simple Local RAG Pipeline

# Overview
This project aims to build a Retrieval Augmented Generation (RAG) pipeline from scratch, designed to run on a local GPU. The goal is to be able to open a PDF file, ask questions about its contents, and receive answers generated by a Large Language Model (LLM).

# What is RAG?
RAG stands for Retrieval Augmented Generation. It was introduced in the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. The RAG process involves three main steps:

# Retrieval: Seeking relevant information from a source given a query. For example, getting relevant passages of text from a database given a question.
# Augmentation: Using the retrieved information to modify the input to a generative model (e.g., an LLM).
# Generation: Generating an output based on the augmented input. For instance, generating a passage of text given an input prompt.

# Why RAG?
The primary goal of RAG is to improve the accuracy and relevance of generated outputs by leveraging external information retrieved from a database or document.

# Installation
To run this project, you'll need to have Python installed along with the necessary libraries. You can install the required libraries using the following command:

Copy code
pip install -r requirements.txt

# Usage
1. Clone the Repository
git clone <repository_url>
cd <repository_directory>

2.Open the Jupyter Notebook
Launch Jupyter Notebook and open the DocuBot.ipynb file.

# Give Command
jupyter notebook
Run the Notebook

# Follow the steps in the notebook to set up the RAG pipeline. The notebook will guide you through the process of:

Importing and setting up the necessary libraries.

Loading and processing a PDF file.

Embedding the text chunks.

Retrieving relevant information.

Generating answers to your queries using a Large Language Model.

# Author
This project was developed by Pratyush Tiwari.

# License
This project is licensed under the MIT License. See the LICENSE file for more details.

# Acknowledgments
The inspiration for this project comes from the frameworks LlamaIndex and LangChain.
Special thanks to the authors of the paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks for their foundational work in this area.
